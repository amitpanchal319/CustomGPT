{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9PygRWMNLOLI"
   },
   "outputs": [],
   "source": [
    "!pip install -q groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xbeLDDo0LREA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_ylHEDYVLRG3"
   },
   "outputs": [],
   "source": [
    "# Set up Groq client with API key\n",
    "client = Groq(\n",
    "    api_key=\"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\"  # Or directly input your API key here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bprDRJFwLRJ9"
   },
   "outputs": [],
   "source": [
    "def generate_response(user_query):\n",
    "    \"\"\"\n",
    "    Generate a response for any user query using Groq's API, with no hard-coding of topics.\n",
    "    The model is expected to handle diverse topics dynamically.\n",
    "    \"\"\"\n",
    "    # System message that instructs the model to answer any query across various topics\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant capable of answering questions on a wide range of topics, \"\n",
    "        \"including programming, history, science, general knowledge, mathematics, education, and more. \"\n",
    "        \"Provide clear, concise, and accurate answers to any question the user asks.\"\n",
    "    )\n",
    "\n",
    "    # User's question\n",
    "    user_message = user_query\n",
    "\n",
    "    # Create the chat completion using Groq API\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        model=\"mixtral-8x7b-32768\"  # Use the appropriate model for general use\n",
    "    )\n",
    "\n",
    "    # Return the response content\n",
    "    return chat_completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KIWts8-KLRMt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is Backward propogation in Neural networks and how it works step by step?\n",
      "AI: Backpropagation, short for \"backward propagation of errors,\" is a method used in artificial neural networks to calculate the gradient that is needed in the calculation of the weights to be used in the network. It is commonly used during the training process of the network, and it is a key algorithm that powers much of deep learning.\n",
      "\n",
      "Here's a step-by-step explanation of how backpropagation works:\n",
      "\n",
      "1. **Forward Propagation:** The first step in the backpropagation algorithm is to perform a forward pass through the network, in which inputs are propagated through the network, layer by layer, until an output is produced. During this forward pass, the output of each neuron is computed as the weighted sum of its inputs, passed through a non-linear activation function.\n",
      "\n",
      "2. **Compute Output Error:** Once the output of the network has been computed, the error between the network's output and the desired output is calculated. This error is used to update the weights of the network during the backpropagation step.\n",
      "\n",
      "3. **Backward Propagation:** The backpropagation step involves computing the gradient of the error with respect to the weights of the network. This is done by propagating the error backwards through the network, layer by layer, starting from the output layer and moving towards the input layer. During this backpropagation step, the derivative of the activation function is used to compute the gradient.\n",
      "\n",
      "4. **Update Weights:** Once the gradient has been computed, the weights of the network are updated using a method called gradient descent. In gradient descent, the weights are adjusted in the direction that minimally reduces the error.\n",
      "\n",
      "5. **Iterate:** The above steps are repeated for multiple iterations until the error between the network's output and the desired output is minimized.\n",
      "\n",
      "In summary, backpropagation is a method for computing the gradient of the error with respect to the weights of a neural network, which is used to update the weights during the training process. It works by propagating the error backwards through the network, layer by layer, and computing the gradient at each step. The weights are then updated using gradient descent, and this process is repeated for multiple iterations until the error is minimized.\n"
     ]
    }
   ],
   "source": [
    "# 1. Programming-related query\n",
    "programming_query = \"What is Backward propogation in Neural networks and how it works step by step?\"\n",
    "print(\"User:\", programming_query)\n",
    "print(\"AI:\", generate_response(programming_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3HZFSwOPLRPW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! You can ask any question, and I will provide the answer. Type 'exit' to end the conversation.\n",
      "\n",
      "AI: Yes, I am here to help you. Please ask me a question and I will do my best to provide a clear, concise, and accurate answer.\n",
      "AI: Hello! I'm here to help. Please feel free to ask me any questions you have on programming, history, science, general knowledge, mathematics, education, or any other topic. I'll do my best to provide clear, concise, and accurate answers. Let's get started!\n",
      "AI: I will do my best to provide clear, concise, and accurate answers to any question you have. However, please keep in mind that while I have a wide range of knowledge, I am not perfect and there may be some questions that I am unable to answer. When that is the case, I will do my best to help you find the information you are looking for. To get started, what would you like to know?\n",
      "AI: Yes, I am capable of answering questions on a wide range of topics, including programming, history, science, general knowledge, mathematics, education, and more. I will strive to provide clear, concise, and accurate answers to any question you ask. Please go ahead and ask me something.\n",
      "AI: Yes, I am a helpful assistant and I will do my best to provide clear, concise, and accurate answers to any questions you have on a wide range of topics including programming, history, science, general knowledge, mathematics, education and more. Please go ahead and ask me a question.\n",
      "AI: I will do my best to provide clear, concise, and accurate answers to any questions you have. To get started, please ask me a question by typing it in the prompt. I can help with topics such as programming, history, science, general knowledge, mathematics, education, and more.\n",
      "AI: Yes, I am here to help you with any questions you have to the best of my ability. I will strive to provide clear, concise, and accurate answers. Please go ahead and ask me a question.\n",
      "AI: Sure, I'm here to help! Just ask me any question you have in mind, and I'll do my best to provide a clear, concise, and accurate answer. Let's get started!\n",
      "AI: Yes, I am a helpful assistant capable of answering questions on a wide range of topics, including programming, history, science, general knowledge, mathematics, education, and more. I will do my best to provide clear, concise, and accurate answers to any question you ask. Please keep in mind that I am an AI and my knowledge cutoff is 2021, so I may not be able to answer the most recent events or developments. How can I help you today?\n",
      "AI: Of course! I'll do my best to provide clear, concise, and accurate answers to any question you have. Please go ahead and ask me something.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Start the interactive chat\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m interactive_chat()\n",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m, in \u001b[0;36minteractive_chat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWelcome! You can ask any question, and I will provide the answer. Type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to end the conversation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Get user input\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Check if the user wants to exit the conversation\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Amit Panchal\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Amit Panchal\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"\n",
    "    Start an interactive chat session where the user can ask any question across a variety of topics.\n",
    "    \"\"\"\n",
    "    print(\"Welcome! You can ask any question, and I will provide the answer. Type 'exit' to end the conversation.\\n\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        # Check if the user wants to exit the conversation\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Exiting the chat...\")\n",
    "            break\n",
    "\n",
    "        # Get the AI's response for the user's query\n",
    "        response = generate_response(user_input)\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "# Start the interactive chat\n",
    "interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18_EACGcLRSH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0P7ev0fOLRXc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwGQOE5pLRaD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLGHiW78LRfl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQFOrAARRM7X"
   },
   "source": [
    "# memory updated.........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEzCC4fWLRip"
   },
   "outputs": [],
   "source": [
    "!pip install -q groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_YoerLMLRl1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiajmzRsRMW1"
   },
   "outputs": [],
   "source": [
    "# Set up Groq client with API key\n",
    "client = Groq(\n",
    "    api_key=\"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\"  # Or directly input your API key here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GN5Y04YRMIn"
   },
   "outputs": [],
   "source": [
    "# Initialize conversation history with instructions to provide concise and clear answers\n",
    "conversation_history = [\n",
    "    {\"role\": \"system\", \"content\":\n",
    "     \"You are a highly capable and helpful assistant, trained to answer a wide variety of questions on various topics. \"\n",
    "     \"Your main goal is to assist users by providing clear, concise, and accurate answers. \"\n",
    "     \"When responding to a user's query, keep your answers short, focused, and easy to understand, without unnecessary details. \"\n",
    "     \"Only provide more detailed explanations if the user specifically requests more information (e.g., 'explain in more detail', 'elaborate', 'provide further explanation'). \"\n",
    "     \"If the user is asking a complex question, break down your response into manageable chunks and provide step-by-step explanations where needed. \"\n",
    "     \"Be polite and encouraging, and make sure to provide accurate information at all times. \"\n",
    "     \"You should also remember all previous exchanges in the conversation and use that information to provide better context and relevant responses.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TT7jk1iRMFd"
   },
   "outputs": [],
   "source": [
    "def generate_response_with_memory(user_query):\n",
    "    \"\"\"\n",
    "    Generate a response for any user query, while keeping track of the conversation history.\n",
    "    The model will remember previous exchanges for context.\n",
    "    \"\"\"\n",
    "    # Add the user's message to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "\n",
    "    # Create the chat completion using Groq API with the updated conversation history\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=conversation_history,\n",
    "        model=\"mixtral-8x7b-32768\"  # Use the appropriate model for general use\n",
    "    )\n",
    "\n",
    "    # Get the AI's response\n",
    "    ai_response = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Add the AI's response to the conversation history\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "\n",
    "    # Return the response\n",
    "    return ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3WitV_qRMDR"
   },
   "outputs": [],
   "source": [
    "def interactive_chat_with_memory():\n",
    "    \"\"\"\n",
    "    Start an interactive chat session where the user can ask any question and the model remembers previous exchanges.\n",
    "    \"\"\"\n",
    "    print(\"Welcome! You can ask any question, and I will provide the answer. I remember everything you ask!\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        print(\"\")\n",
    "        user_input = input(\"You: \")\n",
    "\n",
    "        # Check if the user wants to exit the conversation\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Exiting the chat...\")\n",
    "            break\n",
    "\n",
    "        # Get the AI's response for the user's query, using memory\n",
    "        response = generate_response_with_memory(user_input)\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "# Start the interactive chat with memory\n",
    "interactive_chat_with_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qLfjsJ1RL-A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4YZprbSRL7l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_c5mWbJRL4_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN6uqewOPomdsX00/81WqEy",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
